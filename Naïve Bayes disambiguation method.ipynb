{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fccb6c",
   "metadata": {},
   "source": [
    "# Implement decision rule-based NaÃ¯ve Bayes disambiguation method to find the sense of an ambiguous word with the given training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f619fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required modules\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bdab06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of training set:5\n",
      "Enter the class of sence 1\n",
      "fish\n",
      "Enter the training data of sence 1\n",
      "bass eat super\n",
      "Enter the class of sence 2\n",
      "fish\n",
      "Enter the training data of sence 2\n",
      "bass lunch excellent\n",
      "Enter the class of sence 3\n",
      "fish\n",
      "Enter the training data of sence 3\n",
      "bass ate like\n",
      "Enter the class of sence 4\n",
      "music\n",
      "Enter the training data of sence 4\n",
      "bass play music\n",
      "Enter the class of sence 5\n",
      "music\n",
      "Enter the training data of sence 5\n",
      "bass interest play\n",
      "\n",
      " Training Set: [['fish', ['bass', 'eat', 'super']], ['fish', ['bass', 'lunch', 'excellent']], ['fish', ['bass', 'ate', 'like']], ['music', ['bass', 'play', 'music']], ['music', ['bass', 'interest', 'play']]]\n",
      "\n",
      " Vacablory(10):  ['bass', 'eat', 'super', 'lunch', 'excellent', 'ate', 'like', 'play', 'music', 'interest']\n"
     ]
    }
   ],
   "source": [
    "#Get the training set data from the user\n",
    "n = int(input(\"Enter the number of training set:\"))\n",
    "train_data = []\n",
    "V = []\n",
    "for i in range(n):\n",
    "    print(\"Enter the class of sence\",i+1)\n",
    "    cls = input()\n",
    "    print(\"Enter the training data of sence\",i+1)\n",
    "    data = input()\n",
    "    sent_tokens = sent_tokenize(data)\n",
    "    word_tokens = []\n",
    "    for sentence in sent_tokens :\n",
    "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "        word_token = word_tokenize(sentence)\n",
    "        for word in word_token:\n",
    "            if word not in V:\n",
    "                V.append(word)\n",
    "        word_tokens += word_token\n",
    "    train_data.append([cls,word_tokens])\n",
    "cV = len(V) #Count of Vacablory\n",
    "print(\"\\n Training Set:\",train_data)\n",
    "print(f\"\\n Vacablory({cV}): \",V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71902298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts: {'fish': 3, 'music': 2}\n",
      "Probability of classes {'fish': 0.26666666666666666, 'music': 0.2}\n"
     ]
    }
   ],
   "source": [
    "#finding the count of each class\n",
    "c_cls = {}\n",
    "for cls in train_data:\n",
    "    if cls[0] in c_cls:\n",
    "        c_cls[cls[0]]+=1\n",
    "    else:\n",
    "        c_cls[cls[0]]=1\n",
    "\n",
    "print(\"class counts:\",c_cls)\n",
    "\n",
    "# find probability of each class(Laplace Law)\n",
    "p_cls = {}\n",
    "for cls in c_cls:\n",
    "    p_cls[cls] = (c_cls[cls]+1)/(cV+n) \n",
    "\n",
    "print(\"Probability of classes\", p_cls)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11991bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count words in respective class [{'fish': {'bass': 3, 'eat': 1, 'super': 1, 'lunch': 1, 'excellent': 1, 'ate': 1, 'like': 1}}, {'music': {'bass': 2, 'play': 2, 'music': 1, 'interest': 1}}]\n"
     ]
    }
   ],
   "source": [
    "#finding the count of all words in respective class\n",
    "c_w_cls = []\n",
    "\n",
    "for cls in c_cls:\n",
    "    cwords = {}\n",
    "    for data in train_data:\n",
    "        if cls==data[0]:\n",
    "            for word in data[1]:\n",
    "                if word in cwords:\n",
    "                    cwords[word] += 1\n",
    "                else:\n",
    "                    cwords[word] = 1\n",
    "    c_w_cls.append({cls:cwords})\n",
    "\n",
    "\n",
    "print(\"Count words in respective class\",c_w_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f44c3157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional Probabilities: {'fish': {'bass': 0.3076923076923077, 'eat': 0.15384615384615385, 'super': 0.15384615384615385, 'lunch': 0.15384615384615385, 'excellent': 0.15384615384615385, 'ate': 0.15384615384615385, 'like': 0.15384615384615385}, 'music': {'bass': 0.25, 'play': 0.25, 'music': 0.16666666666666666, 'interest': 0.16666666666666666}}\n"
     ]
    }
   ],
   "source": [
    "#conditional probablility of word|class using add 1 smoothing techinque\n",
    "cp_w_cls = {}\n",
    "\n",
    "for clss in c_w_cls:\n",
    "    pwords = {}\n",
    "    for cls in clss:\n",
    "        for word in clss[cls]:\n",
    "            prob = (clss[cls][word]+1)/(c_cls[cls]+cV)\n",
    "            pwords[word]=prob\n",
    "    cp_w_cls[cls] = pwords\n",
    "\n",
    "print(\"conditional Probabilities:\",cp_w_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9545f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the test data\n",
      "bass super excellent play\n",
      "Test tokens: ['bass', 'super', 'excellent', 'play']\n"
     ]
    }
   ],
   "source": [
    "#Getting the input of the test data form user\n",
    "print(\"Enter the test data\")\n",
    "data = input()\n",
    "sent_tokens = sent_tokenize(data)\n",
    "test_tokens = []\n",
    "for sentence in sent_tokens :\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    test_tokens += word_tokenize(sentence)\n",
    "\n",
    "print(\"Test tokens:\", test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85460df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores of each sence: {'fish': -3.825684694299141, 'music': -4.061452479087193}\n",
      "The Test set ['bass', 'super', 'excellent', 'play'] belong to fish\n"
     ]
    }
   ],
   "source": [
    "#Calculating the scores\n",
    "score = {}\n",
    "\n",
    "for cls in cp_w_cls:\n",
    "    cls_scr = p_cls[cls]\n",
    "    for word in test_tokens:\n",
    "        if word in cp_w_cls[cls]:\n",
    "            cls_scr *= (cp_w_cls[cls][word])\n",
    "        else:\n",
    "            cls_scr *= (1/(c_cls[cls]+cV))\n",
    "    score[cls] = math.log10(cls_scr)\n",
    "    \n",
    "print(\"Scores of each sence:\", score)\n",
    "\n",
    "#Displaying the final outcome\n",
    "maxv = -9999\n",
    "maxc = \"unknown\"\n",
    "for cls in c_cls:\n",
    "    if score[cls]>maxv:\n",
    "        maxv = score[cls]\n",
    "        maxc = cls\n",
    "print(f\"The Test set {test_tokens} belong to {maxc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
