{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681f8372",
   "metadata": {},
   "source": [
    "# Implement t-Test and Chi-Square test\n",
    "## To check whether a given sequence of words is acollocation or not.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956255bb",
   "metadata": {},
   "source": [
    "#### Importing Modules and gathering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb411d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required module\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "import string\n",
    "import math\n",
    "from scipy.stats import t,chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aafc855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "data = gutenberg.raw('austen-emma.txt')\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed6508",
   "metadata": {},
   "source": [
    "#### Pre-Processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e599a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "sent_tokens = sent_tokenize(data)\n",
    "word_tokens = []\n",
    "for sentence in sent_tokens :\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    word_tokens += word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e9068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopwords removal    \n",
    "stops = set(stopwords.words('english'))\n",
    "word_tokens = [word for word in word_tokens if word.lower() not in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2f6c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL WORDS IN THE CORPUS : 72767\n",
      "UNIQUE WORDS : 9509\n"
     ]
    }
   ],
   "source": [
    "#Frequency, Propability\n",
    "unique_words = set(word_tokens)\n",
    "print(f\"TOTAL WORDS IN THE CORPUS : {len(word_tokens)}\")\n",
    "print(f\"UNIQUE WORDS : {len(unique_words)}\")\n",
    "\n",
    "frequency = {word : word_tokens.count(word) for word in unique_words}\n",
    "propability = {word : frequency[word]/len(word_tokens) for word in unique_words}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a3ef0",
   "metadata": {},
   "source": [
    "#### Generating Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64ac107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL UNIQUE BIGRAMS : 60090\n"
     ]
    }
   ],
   "source": [
    "#Generating Bigrams, frequency and propability of bigrams\n",
    "bigrams = zip(word_tokens[:-1], word_tokens[1:])\n",
    "bigram_freq = {}\n",
    "bigram_count = 0\n",
    "for bigram in bigrams :\n",
    "    bigram_count += 1\n",
    "    if bigram in bigram_freq :\n",
    "        bigram_freq[bigram] += 1\n",
    "    else :\n",
    "        bigram_freq[bigram] = 1\n",
    "bigram_prop = {}\n",
    "for bigram, freq in bigram_freq.items() : \n",
    "    bigram_prop[bigram] = freq/bigram_count\n",
    "print(\"TOTAL UNIQUE BIGRAMS :\", len(bigram_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8606767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bigram_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68157d07",
   "metadata": {},
   "source": [
    "### t-Test Demonstratoin\n",
    "\n",
    "#### t = (X – μ) / (σ / √n)\n",
    "\n",
    "\n",
    "t = t-value \n",
    "\n",
    "X = sample mean \n",
    "\n",
    "μ = true/population mean \n",
    "\n",
    "σ = standard deviation \n",
    "\n",
    "n = sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699bb1a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055 COLLOCATIONS IN THE CORPUS DETERMINED FROM T-TEST : \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_colloc = []\n",
    "n = len(word_tokens)\n",
    "t_critical = t.ppf(1-0.05,n-1)\n",
    "for bigram,prop in bigram_prop.items():\n",
    "    w1,w2 = bigram\n",
    "    mu = propability[w1] * propability[w2]\n",
    "    X_mean = prop\n",
    "    t_stat = (X_mean -  mu)/(math.sqrt(((X_mean)*(1-X_mean))/n))\n",
    "    if t_stat > t_critical:\n",
    "        t_colloc.append((bigram,t_stat))\n",
    "print(f\"{len(t_colloc)} COLLOCATIONS IN THE CORPUS DETERMINED FROM T-TEST : \\n\")\n",
    "# print(t_colloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995dc50",
   "metadata": {},
   "source": [
    "### Chi^2 TEST demonstration\n",
    "\n",
    "#### X2 = Sum(i,j=1,2) ((Oij - Eij)2 / Eij )\n",
    "\n",
    "O - Observed Frequencies\n",
    "\n",
    "E - Excepcted frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0758874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53796 COLLOCATIONS IN THE CORPUS DETERMINED FROM CHI^2-TEST : \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chi_colloc = []\n",
    "n = len(word_tokens)\n",
    "chi_critical = chi2.ppf(1-0.05, 1)\n",
    "for bigram, prop in bigram_prop.items() :\n",
    "    w1, w2 = bigram\n",
    "    f1 = frequency[w1]\n",
    "    f2 = frequency[w2]\n",
    "    #Observed Frequencies\n",
    "    o_1_2 = bigram_freq[bigram]\n",
    "    o_n1_2 = f2 - o_1_2\n",
    "    o_1_n2 = f1 - o_1_2\n",
    "    o_n1_n2 = n - (o_1_2 + o_n1_2 + o_1_n2)\n",
    "    obs = [o_1_2, o_n1_2, o_1_n2, o_n1_n2]\n",
    "    #Excepcted frequencies\n",
    "    e_1_2 = (f1 * f2)/n\n",
    "    e_n1_2 = ((n - f1) * f2)/n\n",
    "    e_1_n2 = (f1 * (n - f2))/n\n",
    "    e_n1_n2 = ((n - f1)*(n - f2))/n\n",
    "    exp = [e_1_2, e_n1_2, e_1_n2, e_n1_n2]\n",
    "    chi_stat = sum( ((obs[i] - exp[i])**2)/exp[i] for i in range(4))\n",
    "    if chi_stat > chi_critical :\n",
    "        chi_colloc.append(bigram)\n",
    "print(f\"{len(chi_colloc)} COLLOCATIONS IN THE CORPUS DETERMINED FROM CHI^2-TEST : \\n\")\n",
    "# print(chi_colloc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
